<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Open3DIS">
  <meta name="keywords" content="Open3DIS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Open3DIS </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="css/style.css"> <!-- Resource style -->
  <script src="js/modernizr.js"></script> <!-- Modernizr -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>


  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    .rcorners1 {
      border-radius: 10px;
      background: #ffffffd0;
      padding: 5px;
      font-size: 120%;
      color: #5c5c5c;
    }
  </style>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Open3DIS <br />
              <p class="title is-3 publication-title">Open-Vocabulary 3D Instance Segmentation <br /> with 2D Mask Guidance</p>
              <p class="title is-3 publication-title">CVPR 2024</p>
            </h1>
            <!-- <h1 class="title is-4" style="color: #5c5c5c;">ICCV 2023</h1> -->

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://github.com/PhucNDA/">Phuc Nguyen</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="https://ngoductuanlhp.github.io/">Tuan Duc Ngo</a><sup>*1,4</sup>,
              </span>
              <span class="author-block">
                <a href="https://people.cs.umass.edu/~kalo/">Evangelos Kalogerakis</a><sup>4</sup>,
              </span>
              <span class="author-block">
                <a href="https://people.csail.mit.edu/ganchuang/">Chuang Gan</a><sup>2,4</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Anh Tran</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/view/cuongpham/home">Cuong Pham</a><sup>1,3</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.khoinguyen.org/">Khoi Nguyen</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block" style="margin-right: 1em;"><sup>1</sup>VinAI Research</span>
              <span class="author-block" style="margin-right: 1em;"><sup>2</sup>MIT-IBM Watson AI Lab</span>
              <span class="author-block" style="margin-right: 1em;"><sup>3</sup>Posts & Telecommunications Inst. of Tech.</span>
              <span class="author-block" style="margin-right: 1em;"><sup>4</sup>UMass Amherst</span>
            
            <div class="is-size-5 publication-authors"></div>
              <span class="author-block" style="margin-right: 1em;"><sup>*</sup>Equal contribution</span>
            </div>
            <!-- Link-->
            <span class="link-block">
              <a href="https://arxiv.org/abs/2312.10671" class="external-link button is-normal is-rounded is-dark" enabled>
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>

            <span class="link-block">
              <a href="assets/Open3DIS_supplementary.pdf" class="external-link button is-normal is-rounded is-dark" enabled>
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a>
            </span>
            
            <span class="link-block">
              <a href="assets/Open3DIS_40mb.pdf" class="external-link button is-normal is-rounded is-dark" disabled>
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>

            <span class="link-block">
              <a href="" class="external-link button is-normal is-rounded is-dark" disabled>
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code (coming soon)</span>

              </a>
            </span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
    </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="assets/teaser.png" style="max-width:100%" />
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              <b>
                TL;DR: We propose Open3DIS addressing 3D Instance Segmentation with Open-Vocabulary queries.
              </b>
              <br /><br />

              We introduce <b>Open3DIS </b>, a novel solution designed to tackle the problem of Open-Vocabulary Instance Segmentation within 3D scenes. Objects within 3D environments exhibit diverse shapes, scales, and colors, making precise instance-level identification a challenging task. Recent advancements in Open-Vocabulary scene understanding have made significant strides in this area by employing class-agnostic 3D instance proposal networks for object localization and learning queryable features for each 3D mask. While these methods produce high-quality instance proposals, they struggle with identifying small-scale and geometrically ambiguous objects. The key idea of our method is a new module that aggregates 2D instance masks across frames and maps them to geometrically coherent point cloud regions as high-quality object proposals addressing the above limitations. These are then combined with 3D class-agnostic instance proposals to include a wide range of objects in the real world. 
              To validate our approach, we conducted experiments on three prominent datasets, including ScanNet200, S3DIS, and Replica, demonstrating significant performance gains in segmenting objects with diverse categories over the state-of-the-art approaches.             </p>
                
          </div>
          <br /><br />
          <figure class="cd-image-container">
            <img src="assets/3dproposal.png" alt="Original Image">
            <span class="cd-image-label" data-type="original">
            </span>

            <div class="cd-resize-img" style="border-right: 2px dotted rgb(94, 94, 94);">
              <!-- the resizable image on top -->
              <img src="assets/pcloud.png" alt="Modified Image">
              <span class="cd-image-label" data-type="modified">
              </span>
            </div>

            <span class="cd-handle"></span>
          </figure> <!-- cd-image-container -->
        </div>
      </div>

      <!--Method-->

      <br /><br />
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Method</h2>

            <div class="container is-max-desktop">
              <div class="hero-body">
                <img src="assets/method.png" style="max-width:100%" />
                <h2 class="subtitle has-text-centered">
                </h2>
              </div>
            </div>
            <div class="content has-text-justified">
            <p>
              A pre-trained class-agnostic 3D Instance Segmenter proposes initial 3D objects, while a 2D Instance Segmenter generates masks for video frames. Our 2D-guide-3D Instance Proposal Module combines superpoints and 2D instance masks to enhance 3D proposals, integrating them with the initial 3D proposals. Finally, the Pointwise Feature Extraction module correlates instance-aware point cloud CLIP features from multiview images with text embeddings to generate the ultimate instance masks.  
            </p>
          </div>
            <div class="container is-max-desktop">
              <div class="hero-body">
                <img src="assets/2d-3d-maskguide.png" style="max-width:100%" />
                <h2 class="subtitle has-text-centered">
                </h2>
              </div>
            </div>

            <div class="content has-text-justified">
            <p>
              (Top) The 2D-G-3DIP module utilizes 2D per-frame instance masks to generate per-frame 3D proposals by leveraging 3D superpoints. (Bottom) Our proposed hierarchical merging. These proposals are considered point cloud regions and undergo a hierarchical merging process across multiple views, resulting in the final Augmented 3D proposals
            </p>                    
            </div>
          </div>
        </div>

      <!-- Concurrent Work. -->

      <br /><br />
      <div class="columns is-centered">
        <div class="column is-full-width">
          <p id="explanatory-video"></p>
          <h2 class="title is-3">Demo Instance-Aware Point Cloud Features</h2>
          <video controls poster="assets/starter_gui.png">
            <source src="assets/Open3DIS_demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          
          <br /><br />

          <h2 class="title is-3">Quantitative Results</h2>
          <p class="title is-3 mt-5 has-text-centered"> ScanNet200 </p>
              <p class="content is-size-6 has-text-justified">
                OV-3DIS results on <b>ScanNet200</b>. Our proposed method achieves the highest AP, outperforming previous methods in all metrics. The best results are in <b>bold</b>. [Using 3D backbone ISBNet or Mask3D gains no significant different. Below 3D exps use ISBNet] (updated on 2024, Mar. 19th).
              </p>
              <p>
                \[
                \begin{array}{lccccccc}
                \hline
                \textbf{Method} & \text{Backbone3D} & \textbf{AP} & \textbf{AP$_{50}$} & \textbf{AP$_{25}$}  & \textbf{AP$_{head}$} & \textbf{AP$_{com}$} & \textbf{AP$_{tail}$}  \\
                \hline
                \text{OpenScene} & \text{DBScan} & 2.8 & 7.8 & 18.6 & 2.7 & 3.1 & 2.6 \\
                \text{OpenScene} & \text{Mask3D} & 11.7 & 15.2 & 17.8 & 13.4 & 11.6 & 9.9 \\
                \text{SAM3D (SAM)} &  &  6.1 & 14.2 & 21.3 & 7.0 & 6.2 & 4.6 \\
                \text{OVIR-3D (G-SAM)} &  & 13.0 & 24.9 & 32.3 & 14.4 & 12.7 & 11.7 \\
                \text{OpenIns3D (Synthetic-Scene)} & \text{Mask3D} & 8.8 & 10.3 & 14.4 & 16.0 & 6.5 & 4.2 \\
                \text{OpenMask3D} & \text{Mask3D} & 15.4 & 19.9 & 23.1 & 17.1 & 14.1 & 14.9 \\
                \hline
                \textbf{Ours} \text{ (G-SAM)} &  & 18.2 & {26.1} & 31.4 & 18.9 & 16.5 & {19.2} \\
                \textbf{Ours} \text{ (3D)} & \text{ISBNet} & {18.6} & 23.1 & 27.3 & {24.7} & {16.9} & 13.3 \\
                \textbf{Ours} \text{ (3D)} & \text{Mask3D} & {18.9} & 24.3 & 28.3 & {23.9} & {17.4} & 15.3 \\
                \textbf{Ours} \text{ (3D + G-SAM)} & \text{ISBNet} &  \textbf{23.7}& \textbf{29.4} & {32.8} & \textbf{27.8} & {21.2} & {21.8} \\
                \textbf{Ours} \text{ (3D + G-SAM)} & \text{Mask3D} & \textbf{23.7} & {29.2} & \textbf{33.1} & 26.4 & \textbf{22.5} & \textbf{21.9} \\
                \hline
                \end{array}
                \]
              </p>

              <p class="content is-size-6 has-text-justified">
                Class-agnostic 3DIS evalutaion results on <b>ScanNet200</b>! (updated on 2024, Mar. 25th) [not in arxiv Dec. 17th] *: unofficial.
              </p>
              <p>
                \[
                \begin{array}{lccc}
                \hline
                \textbf{Method} & \textbf{AP} & \textbf{AP$_{50}$} & \textbf{AP$_{25}$}  & \textbf{AR} & \textbf{AR$_{50}$} & \textbf{AR$_{25}$}  \\
                \hline
                \text{Superpoint} & 5.0 & 12.7 & 38.9 \\
                \text{DBSCAN} & 1.6 & 5.5 & 32.1 \\
                \text{UnScene3D}  & 15.9 & 32.2 & 58.5 \\
                \text{SAM3D (SAM)}  & 20.2 & 54.0 & 30.3 \\
                \text{OVIR-3D* (Detic)} & 14.4 & 27.5 & 38.8 \\
                \text{Mask Clustering (CropFormer)} & 17.4 & 33.3 & 46.7 \\
                \text{SAI3D (SAM)}  & 30.8 & 50.5 & 70.6 \\
                \hline
                \textbf{Ours} \text{ (G-SAM)} & 29.7 & 45.2	& 56.8 & 49.0 & 70.0 & 83.2 \\
                \textbf{Ours} \text{ (3D)} & 40.2 & 50.0 & 54.6 & 66.8 & 80.4 & 87.4 \\
                \textbf{Ours} \text{ (3D + G-SAM)} & 34.6 & 43.1 & 48.5 & 66.2 & 81.6 & 91.4 \\
                \textbf{Ours} \text{ (3D + SAM)} & 41.5 & 51.6 & 56.3 & 74.8 & 90.9 & 97.8 \\
                \hline
                \end{array}
                \]
              </p>

          <p class="title is-3 mt-5 has-text-centered"> ScanNet++ </p>
            <p class="content is-size-6 has-text-justified">
              Class-agnostic 3DIS evalutaion results on <b>ScanNet++</b>. (updated on 2024, Mar. 28th) [not in arxiv Dec. 17th].            </p>
            <p>
              \[
              \begin{array}{lccc}
              \hline
              \textbf{Method} & \textbf{AP} & \textbf{AP$_{50}$} & \textbf{AP$_{25}$}  & \textbf{AR} & \textbf{AR$_{50}$} & \textbf{AR$_{25}$}  & \textbf{NOTE} \\
              \hline
              \text{ISBNet (3D)} & 6.2 & 10.1  &	16.2  & 10.9 & 16.9 & 25.2 & \text{pretrained Scannet200}&\\
              \hline
              \text{SAM3D} & 7.2 & 14.2 & 29.4 &\\
              \text{SAM-guided Graph Cut} & 12.9 & 25.3 & 43.6 &\\
              \text{Segment3D} & 12.0 & 22.7 & 37.8 &\\
              \text{SAI3D (SAM)}  & 17.1 & 31.1 & 49.5 &\\
              \hline
              \textbf{Ours} \text{(SAM)} & 18.5 & 33.5	& 44.3 &	35.6 & 63.7	 & 82.7 &  \text{100 frames per scene}&\\
              \hline
              \end{array}
              \]
            </p>
              <!-- <p class="title is-3 mt-5 has-text-centered"> Replica </p>
              <p class="content is-size-6 has-text-justified">
                OV-3DIS results on <b>Replica</b>.
              </p>
              <p>
                \[
                \begin{array}{lccc}
                \hline
                \textbf{Method} & \textbf{AP} & \textbf{AP$_{50}$} & \textbf{AP$_{25}$}   \\
                \hline
                \text{OpenScene + DBScan}  & 10.9 & 15.6 & 17.3 \\ 
                \text{OpenMask3D} & 13.1 & 18.4 & 24.2 \\ 
                \text{OVIR-3D} & 11.1 & 20.5 & 27.5 \\ 
                \hline
                \textbf{Ours} & \textbf{18.1} & \textbf{26.7} & \textbf{30.5} \\
                \hline
                \end{array}
                \]
              </p>

              <p class="title is-3 mt-5 has-text-centered"> S3DIS </p>
              <p class="content is-size-6 has-text-justified">
                OV-3DIS results on <b>S3DIS</b>.
              </p>
              <p>
                \[
                \begin{array}{lcccc}
                \hline
                \textbf{Method} & \multicolumn{2}{c}{\textbf{B8/N4}} & \multicolumn{2}{c}{\textbf{B6/N6}} \\
                & \textbf{AP}$^{B}_{50}$ & \textbf{AP}$^N_{50}$ & \textbf{AP}$^{B}_{50}$ & \textbf{AP}$^N_{50}$ \\
                \midrule
                \text{LSeg-3D}  & 58.3 & 0.3 & 41.1 & 0.5 \\
                \text{PLA} & 59.0 & 8.6 & 46.9 & 9.8 \\
                \text{Lowis3D} & 58.7 & 13.8 & \textbf{51.8} & 15.8 \\
                \hline
                \textbf{Ours} & \textbf{60.8} & \textbf{26.3} & 50.0 & \textbf{29.0} \\
                \hline
                \end{array}
                \]
              </p> -->

          
          <br /><br />
          <h2 class="title is-3">Qualitative Results</h2>
          <figure class="cd-image-container">
            <img src="assets/2d3d.png" alt="Original Image">
            <span class="cd-image-label" data-type="original">
            </span>

            <div class="cd-resize-img" style="border-right: 2px dotted rgb(94, 94, 94);">
              <!-- the resizable image on top -->
              <img src="assets/ovir3d.png" alt="Modified Image">
              <span class="cd-image-label" data-type="modified">
              </span>
            </div>

            <span class="cd-handle"></span>
          </figure>

          <br /><br />
          <h2 class="title is-4">Single Image Lifting</h2>
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img src="assets/singleview.png" style="max-width:100%" />
              <h2 class="subtitle has-text-centered">
                3D instance proposals produced from a single view
              </h2>
            </div>
          </div>
          <h2 class="title is-4">ScanNet200 Benchmark</h2>
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img src="assets/scannet200.png" style="max-width:100%" />
              <h2 class="subtitle has-text-centered">
                3D instance proposals results on ScanNet200. Orange Circle indicates the focus region
              </h2>
            </div>
          </div>

          <h2 class="title is-4">Open-Vocabulary Exploration</h2>
          <div class="container is-max-desktop">
            <div class="hero-body">
              <!-- <img src="assets/openvocab_explore.png" style="max-width:100%" /> -->
              <img src="assets/openvocab_explore.png", width="100%", height="100%" />
              <h2 class="subtitle has-text-centered">
                Open-Vocabulary exploration on ARKitScenes (Left) and ScanNet200 (Right)
              </h2>
            </div>
          </div>



          <h2 class="title is-3">Related Work</h2>
          <div class="content has-text-justified">
          <a href="https://github.com/shiyoung77/OVIR-3D">OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D Data</a>
          <br /><br />
          <a href="https://openmask3d.github.io">OpenMask3D: Open-Vocabulary 3D Instance Segmentation</a>
          <br /><br />
          <a href="https://pengsongyou.github.io/openscene">OpenScene: 3D Scene Understanding with Open Vocabularies</a>

          <p id="bibtex"></p>
          <h2 class="title is-3">BibTeX</h2>
          <pre><code>
            @misc{nguyen2023open3dis,
                  title={Open3DIS: Open-vocabulary 3D Instance Segmentation with 2D Mask Guidance}, 
                  author={Phuc D. A. Nguyen and Tuan Duc Ngo and Chuang Gan and Evangelos Kalogerakis and Anh Tran and Cuong Pham and Khoi Nguyen},
                  year={2023},
                  eprint={2312.10671},
                  archivePrefix={arXiv},
                  primaryClass={cs.CV}
            }
          </code></pre>
        </div>

        <center>
        <!--div class="cd-resize-img" style="border-right: 2px dotted rgb(94, 94, 94);" !-->
          <p>
            <div style="display:none; color:#dedede; font-size:.5em;">
              <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=i_QSG0cs7y2RL4w2Iq7PyYtdj4yhrk8sPhZeGONAnsA&cl=ffffff&w=a"></script>
            </div>
          </p>
        <!--/div !-->
      </center>

        


          
          <!-- <h2 class="title is-3">Publication</h2>
          <div class="content has-text-justified">
          <a href="https://arxiv.org/abs/2212.00786"><img src="assets/paper_preview.jpg" style="max-width:100%" /></a> -->
          <!-- </div>
          <p id="bibtex"></p>
          <h2 class="title is-3">BibTeX</h2>
  
          <pre><code>
@misc{nguyen2023open3dis,
      title={Open3DIS: Open-vocabulary 3D Instance Segmentation with 2D Mask Guidance}, 
      author={Phuc D. A. Nguyen and Tuan Duc Ngo and Chuang Gan and Evangelos Kalogerakis and Anh Tran and Cuong Pham and Khoi Nguyen},
      year={2023},
      eprint={2312.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
            </code></pre>
        </div>
      </div>
      / Concurrent Work. -->

      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                  It borrows the source code of <a href="https://github.com/nerfies/nerfies.github.io">this website</a>.
                  We would like to thank Utkarsh Sinha and Keunhong Park.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>
</body>
<script src="js/jquery-2.1.1.js"></script>
<script src="js/jquery.mobile.custom.min.js"></script> <!-- Resource jQuery -->
<script src="js/main.js"></script> <!-- Resource jQuery -->

</html>
